{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee6b2148",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:13.836284Z",
     "iopub.status.busy": "2023-10-31T11:13:13.835301Z",
     "iopub.status.idle": "2023-10-31T11:13:16.179233Z",
     "shell.execute_reply": "2023-10-31T11:13:16.178078Z"
    },
    "papermill": {
     "duration": 2.356466,
     "end_time": "2023-10-31T11:13:16.182654",
     "exception": false,
     "start_time": "2023-10-31T11:13:13.826188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/home-data-for-ml-course/sample_submission.csv\n",
      "/kaggle/input/home-data-for-ml-course/data_description.txt\n",
      "/kaggle/input/home-data-for-ml-course/train.csv\n",
      "/kaggle/input/home-data-for-ml-course/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07453449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:16.200733Z",
     "iopub.status.busy": "2023-10-31T11:13:16.199262Z",
     "iopub.status.idle": "2023-10-31T11:13:16.982248Z",
     "shell.execute_reply": "2023-10-31T11:13:16.981219Z"
    },
    "papermill": {
     "duration": 0.793816,
     "end_time": "2023-10-31T11:13:16.985355",
     "exception": false,
     "start_time": "2023-10-31T11:13:16.191539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sklearn imports\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c990637",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:17.001002Z",
     "iopub.status.busy": "2023-10-31T11:13:17.000384Z",
     "iopub.status.idle": "2023-10-31T11:13:17.014997Z",
     "shell.execute_reply": "2023-10-31T11:13:17.013320Z"
    },
    "papermill": {
     "duration": 0.025988,
     "end_time": "2023-10-31T11:13:17.018104",
     "exception": false,
     "start_time": "2023-10-31T11:13:16.992116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function definitions\n",
    "def map_feature(X, to_map, mapping):\n",
    "    X[to_map] = X[to_map].stack().apply(lambda x: mapping[x]).unstack()\n",
    "\n",
    "def plot_features(X, features):\n",
    "    fig, axs = plt.subplots(nrows=len(features), figsize=(20, 100))\n",
    "    for i in range(len(features)):\n",
    "        axs[i].scatter(X[features[i]], y)\n",
    "        axs[i].set_xlabel(features[i], fontsize=15)\n",
    "    plt.show()\n",
    "\n",
    "def analyze(data):\n",
    "    print(data.info(), data.describe(), data.value_counts())\n",
    "    \n",
    "def plot_data(data):\n",
    "    sns.scatterplot(x=data,  y=y)\n",
    "    plt.show()\n",
    "    print(data.corr(y), \"\\n\")\n",
    "    \n",
    "def poly_transform(X, features, degree=2):\n",
    "    for col in features:\n",
    "        X[col] = X[col] ** degree\n",
    "    \n",
    "def score_model(model, X_train, y_train, X_valid, y_valid):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f'{model} train accuracy: ', model.score(X_train, y_train).round(3))\n",
    "    print(f'{model} valid accuracy: ', model.score(X_valid, y_valid).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60f08051",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:17.033457Z",
     "iopub.status.busy": "2023-10-31T11:13:17.032961Z",
     "iopub.status.idle": "2023-10-31T11:13:17.195951Z",
     "shell.execute_reply": "2023-10-31T11:13:17.194588Z"
    },
    "papermill": {
     "duration": 0.174168,
     "end_time": "2023-10-31T11:13:17.198975",
     "exception": false,
     "start_time": "2023-10-31T11:13:17.024807",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alley', 'MasVnrType', 'PoolQC', 'Fence', 'MiscFeature'] 5\n",
      "Index(['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual',\n",
      "       'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
      "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF',\n",
      "       'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
      "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
      "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
      "       'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea',\n",
      "       'MiscVal', 'MoSold', 'YrSold'],\n",
      "      dtype='object') 37\n",
      "Index(['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n",
      "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
      "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
      "       'Exterior2nd', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual',\n",
      "       'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating',\n",
      "       'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional',\n",
      "       'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
      "       'PavedDrive', 'SaleType', 'SaleCondition'],\n",
      "      dtype='object') 38\n",
      "(1452, 75) (1459, 75) (1452,)\n"
     ]
    }
   ],
   "source": [
    "#Data preparation\n",
    "X = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/train.csv\")\n",
    "y = X.pop('SalePrice')\n",
    "X_test = pd.read_csv(\"/kaggle/input/home-data-for-ml-course/test.csv\")\n",
    "\n",
    "drop_columns = [col for col in X.columns if X[col].isna().sum() > X.shape[0] // 2]\n",
    "X.drop(drop_columns, axis=1, inplace=True)\n",
    "X_test.drop(drop_columns, axis=1, inplace=True)\n",
    "\n",
    "drop_rows = [523, 1298, 1190, 738, 921, 1350, 1061, 496]\n",
    "X.drop(drop_rows, inplace=True)\n",
    "y.drop(drop_rows, inplace=True)\n",
    "\n",
    "numerical_data = X.select_dtypes(['number']).columns\n",
    "categorical_data = X.select_dtypes(['object']).columns\n",
    "\n",
    "print(drop_columns, len(drop_columns))\n",
    "print(numerical_data, len(numerical_data))\n",
    "print(categorical_data, len(categorical_data))\n",
    "print(X.shape, X_test.shape, y.shape)\n",
    "# X.info(), X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecca8dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:17.213271Z",
     "iopub.status.busy": "2023-10-31T11:13:17.212858Z",
     "iopub.status.idle": "2023-10-31T11:13:17.294200Z",
     "shell.execute_reply": "2023-10-31T11:13:17.293065Z"
    },
    "papermill": {
     "duration": 0.092162,
     "end_time": "2023-10-31T11:13:17.297212",
     "exception": false,
     "start_time": "2023-10-31T11:13:17.205050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ordinal mappings\n",
    "ordinal_mapping0 = {'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1}\n",
    "ordinal_mapping1 = {'Gd': 4, 'Av': 3, 'Mn': 2, 'No': 1}\n",
    "ordinal_mapping2 = {'GLQ': 6, 'ALQ': 5, 'BLQ': 4, 'Rec': 3, 'LwQ': 2, 'Unf': 1}\n",
    "ordinal_mapping3 = {'Y': 2, 'P': 1, 'N': 0}\n",
    "ordinal_mapping4 = {'SBrkr': 5, 'FuseA': 4, 'FuseF': 3, 'FuseP': 2, 'Mix': 1}\n",
    "ordinal_mapping5 = {'Typ': 6, 'Min1': 5, 'Min2': 5, 'Mod': 4, 'Maj1': 3, 'Maj2': 3, 'Sev': 2, 'Sal': 1}\n",
    "ordinal_mapping6 = {'Fin': 3, 'RFn': 2, 'Unf': 1}\n",
    "\n",
    "to_map0 = ['ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual', 'GarageCond']\n",
    "to_map1 = ['BsmtExposure']\n",
    "to_map2 = ['BsmtFinType1', 'BsmtFinType2']\n",
    "to_map3 = ['CentralAir', 'PavedDrive']\n",
    "to_map4 = ['Electrical']\n",
    "to_map5 = ['Functional']\n",
    "to_map6 = ['GarageFinish']\n",
    "\n",
    "map_feature(X, to_map0, ordinal_mapping0)\n",
    "map_feature(X, to_map1, ordinal_mapping1)\n",
    "map_feature(X, to_map2, ordinal_mapping2)\n",
    "map_feature(X, to_map3, ordinal_mapping3)\n",
    "map_feature(X, to_map4, ordinal_mapping4)\n",
    "map_feature(X, to_map5, ordinal_mapping5)\n",
    "map_feature(X, to_map6, ordinal_mapping6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c48a4ca7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:17.313001Z",
     "iopub.status.busy": "2023-10-31T11:13:17.312464Z",
     "iopub.status.idle": "2023-10-31T11:13:17.490610Z",
     "shell.execute_reply": "2023-10-31T11:13:17.488299Z"
    },
    "papermill": {
     "duration": 0.190007,
     "end_time": "2023-10-31T11:13:17.493806",
     "exception": false,
     "start_time": "2023-10-31T11:13:17.303799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1452, 25)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1452 entries, 0 to 1459\n",
      "Data columns (total 25 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   OverallQual      1452 non-null   int64  \n",
      " 1   GrLivArea        1452 non-null   int64  \n",
      " 2   GarageCars       1452 non-null   int64  \n",
      " 3   TotalBsmtSF      1452 non-null   int64  \n",
      " 4   GarageArea       1452 non-null   int64  \n",
      " 5   1stFlrSF         1452 non-null   int64  \n",
      " 6   FullBath         1452 non-null   int64  \n",
      " 7   TotRmsAbvGrd     1452 non-null   int64  \n",
      " 8   YearBuilt        1452 non-null   int64  \n",
      " 9   YearRemodAdd     1452 non-null   int64  \n",
      " 10  GarageYrBlt      1373 non-null   float64\n",
      " 11  MasVnrArea       1444 non-null   float64\n",
      " 12  Fireplaces       1452 non-null   int64  \n",
      " 13  BsmtFinSF1       1452 non-null   int64  \n",
      " 14  ExterQual        1452 non-null   float64\n",
      " 15  KitchenQual      1452 non-null   float64\n",
      " 16  BsmtQual         1415 non-null   float64\n",
      " 17  GarageFinish     1373 non-null   float64\n",
      " 18  HeatingQC        1452 non-null   float64\n",
      " 19  HouseQualCond    1452 non-null   float64\n",
      " 20  TotalArea        1373 non-null   float64\n",
      " 21  TotalSF          1452 non-null   int64  \n",
      " 22  TotalBath        1452 non-null   int64  \n",
      " 23  TotalRms         1452 non-null   int64  \n",
      " 24  OverallQualCond  1452 non-null   float64\n",
      "dtypes: float64(10), int64(15)\n",
      "memory usage: 327.2 KB\n",
      "(1452, 46)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1452 entries, 0 to 1459\n",
      "Data columns (total 46 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   OverallQual      1452 non-null   int64  \n",
      " 1   GrLivArea        1452 non-null   int64  \n",
      " 2   GarageCars       1452 non-null   int64  \n",
      " 3   TotalBsmtSF      1452 non-null   int64  \n",
      " 4   GarageArea       1452 non-null   int64  \n",
      " 5   1stFlrSF         1452 non-null   int64  \n",
      " 6   FullBath         1452 non-null   int64  \n",
      " 7   TotRmsAbvGrd     1452 non-null   int64  \n",
      " 8   YearBuilt        1452 non-null   int64  \n",
      " 9   YearRemodAdd     1452 non-null   int64  \n",
      " 10  GarageYrBlt      1373 non-null   float64\n",
      " 11  MasVnrArea       1444 non-null   float64\n",
      " 12  Fireplaces       1452 non-null   int64  \n",
      " 13  BsmtFinSF1       1452 non-null   int64  \n",
      " 14  ExterQual        1452 non-null   float64\n",
      " 15  KitchenQual      1452 non-null   float64\n",
      " 16  BsmtQual         1415 non-null   float64\n",
      " 17  GarageFinish     1373 non-null   float64\n",
      " 18  HeatingQC        1452 non-null   float64\n",
      " 19  HouseQualCond    1452 non-null   float64\n",
      " 20  TotalArea        1373 non-null   float64\n",
      " 21  TotalSF          1452 non-null   int64  \n",
      " 22  TotalBath        1452 non-null   int64  \n",
      " 23  TotalRms         1452 non-null   int64  \n",
      " 24  OverallQualCond  1452 non-null   float64\n",
      " 25  MSZoning         1452 non-null   object \n",
      " 26  Street           1452 non-null   object \n",
      " 27  LotShape         1452 non-null   object \n",
      " 28  LandContour      1452 non-null   object \n",
      " 29  Utilities        1452 non-null   object \n",
      " 30  LotConfig        1452 non-null   object \n",
      " 31  LandSlope        1452 non-null   object \n",
      " 32  Neighborhood     1452 non-null   object \n",
      " 33  Condition1       1452 non-null   object \n",
      " 34  Condition2       1452 non-null   object \n",
      " 35  BldgType         1452 non-null   object \n",
      " 36  HouseStyle       1452 non-null   object \n",
      " 37  RoofStyle        1452 non-null   object \n",
      " 38  RoofMatl         1452 non-null   object \n",
      " 39  Exterior1st      1452 non-null   object \n",
      " 40  Exterior2nd      1452 non-null   object \n",
      " 41  Foundation       1452 non-null   object \n",
      " 42  Heating          1452 non-null   object \n",
      " 43  GarageType       1373 non-null   object \n",
      " 44  SaleType         1452 non-null   object \n",
      " 45  SaleCondition    1452 non-null   object \n",
      "dtypes: float64(10), int64(15), object(21)\n",
      "memory usage: 565.4+ KB\n"
     ]
    }
   ],
   "source": [
    "#Feature selection & engineering\n",
    "data_corr0 = X[numerical_data].join(y).corr()\n",
    "data_corr1 = X[to_map0 + to_map1 + to_map2 + to_map3 + to_map4 + to_map5 + to_map6].join(y).corr()\n",
    "data_corr_to_y0 = data_corr0.SalePrice.sort_values(ascending=False)[1:]\n",
    "data_corr_to_y1 = data_corr1.SalePrice.sort_values(ascending=False)[1:]\n",
    "#print(data_corr_to_y1)\n",
    "\n",
    "good_features0 = data_corr_to_y0[abs(data_corr_to_y0) >= 0.4].index\n",
    "good_features1 = data_corr_to_y1[abs(data_corr_to_y1) >= 0.4].index\n",
    "bad_features0 = data_corr_to_y0[abs(data_corr_to_y0) <= 0.20].index\n",
    "bad_features1 = data_corr_to_y1[abs(data_corr_to_y1) <= 0.20].index\n",
    "#plot_features(X, bad_features1)\n",
    "\n",
    "pca = PCA(random_state=42)\n",
    "X_pca0 = pca.fit_transform(X[['GrLivArea', 'GarageArea', 'LotArea']])\n",
    "X_pca1 = pca.fit_transform(X[['TotRmsAbvGrd', 'BedroomAbvGr', 'KitchenAbvGr']])\n",
    "# print(\"\\n\", pca.explained_variance_ratio_, \"\\n\")\n",
    "# print(pca.components_.T)\n",
    "\n",
    "X_final = X[good_features0].join(X[good_features1])\n",
    "X_final['HouseQualCond'] = (X[['OverallCond', 'OverallQual', 'HeatingQC', 'FireplaceQu', 'CentralAir', 'Electrical', 'Functional']].sum(axis=1)) * (X.YearBuilt + X.YearRemodAdd + X.GarageYrBlt.fillna(1400) - X.YrSold)\n",
    "X_final['TotalArea'] = X.GrLivArea + ((X.GarageCars + X.GarageFinish) * X.GarageArea)\n",
    "X_final['TotalSF'] = X[['TotalBsmtSF', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'WoodDeckSF', 'OpenPorchSF']].sum(axis=1) - X.LowQualFinSF\n",
    "X_final['TotalBath'] = X[['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath']].sum(axis=1)\n",
    "X_final['TotalRms'] = X.TotRmsAbvGrd - X.BedroomAbvGr\n",
    "X_final['OverallQualCond'] = X[['ExterQual', 'ExterCond', 'KitchenQual', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 'HeatingQC', 'FireplaceQu']].sum(axis=1)\n",
    "\n",
    "to_poly_2 = ['OverallQual', 'YearBuilt', 'TotalSF']\n",
    "to_poly_3 = ['HouseQualCond', 'OverallQualCond']\n",
    "poly_transform(X_final, to_poly_2)\n",
    "poly_transform(X_final, to_poly_3, 3)\n",
    "# plot_features(X_final, X_final.columns)\n",
    "\n",
    "# to_check1 = 'GarageArea'\n",
    "# to_check2 = 'TotalSF'\n",
    "# analyze(X[to_check1])\n",
    "# analyze(X_final[to_check2])\n",
    "# print(\"\\n\", X_final[to_check2][X_final[to_check2] > 0.95e8].index, \"\\n\")\n",
    "# plot_data(X_final.TotalSF)\n",
    "\n",
    "print(X_final.shape)\n",
    "X_final.info(), X_final.describe()\n",
    "\n",
    "X_final = X_final.join(X.select_dtypes([object]))\n",
    "print(X_final.shape)\n",
    "X_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90fb8f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:17.510001Z",
     "iopub.status.busy": "2023-10-31T11:13:17.509514Z",
     "iopub.status.idle": "2023-10-31T11:13:17.574514Z",
     "shell.execute_reply": "2023-10-31T11:13:17.572778Z"
    },
    "papermill": {
     "duration": 0.076749,
     "end_time": "2023-10-31T11:13:17.577475",
     "exception": false,
     "start_time": "2023-10-31T11:13:17.500726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1452, 182) (1452,)\n"
     ]
    }
   ],
   "source": [
    "#Data cleaning\n",
    "num_pipeline = make_pipeline(\n",
    "    SimpleImputer(strategy='constant', fill_value=0), \n",
    "    #SimpleImputer(strategy='median'), \n",
    "    StandardScaler()\n",
    ")\n",
    "cat_pipeline = make_pipeline(\n",
    "    #SimpleImputer(strategy='constant', fill_value='None'), \n",
    "    SimpleImputer(strategy='most_frequent'), \n",
    "    #OneHotEncoder(handle_unknown='ignore')\n",
    ")\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('num', num_pipeline, make_column_selector(dtype_include=np.number)), \n",
    "    ('cat', cat_pipeline, make_column_selector(dtype_include=object))\n",
    "])\n",
    "X_trans = pd.DataFrame(column_transformer.fit_transform(X_final))\n",
    "#X_trans.columns = column_transformer.get_feature_names_out()\n",
    "X_trans = pd.get_dummies(X_trans, columns=range(25, 46))\n",
    "X_trans.columns = X_trans.columns.astype(str)\n",
    "\n",
    "print(X_trans.shape, y.shape)\n",
    "# X_trans.info(), X_trans.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1369ea62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:17.597385Z",
     "iopub.status.busy": "2023-10-31T11:13:17.596550Z",
     "iopub.status.idle": "2023-10-31T11:13:20.621278Z",
     "shell.execute_reply": "2023-10-31T11:13:20.620105Z"
    },
    "papermill": {
     "duration": 3.038249,
     "end_time": "2023-10-31T11:13:20.624184",
     "exception": false,
     "start_time": "2023-10-31T11:13:17.585935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0.2163, '1': 0.0311, '2': 0.0003, '3': 0.0059, '4': 0.0046, '5': 0.0072, '6': 0.0023, '7': 0.0049, '8': 0.0045, '9': 0.0044, '10': 0.0031, '11': 0.006, '12': 0.0011, '13': 0.0114, '14': 0.0013, '15': 0.0027, '16': 0.0018, '17': 0.0009, '18': 0.0006, '19': 0.0831, '20': 0.3552, '21': 0.1772, '22': 0.0117, '23': 0.0053, '24': 0.0303, '25_C (all)': 0.0003, '25_FV': 0.0001, '25_RH': 0.0, '25_RL': 0.0004, '25_RM': 0.0005, '26_Grvl': 0.0, '26_Pave': 0.0, '27_IR1': 0.0006, '27_IR2': 0.0003, '27_IR3': 0.0002, '27_Reg': 0.0005, '28_Bnk': 0.0001, '28_HLS': 0.0005, '28_Low': 0.0002, '28_Lvl': 0.0005, '29_AllPub': 0.0, '29_NoSeWa': 0.0, '30_Corner': 0.0003, '30_CulDSac': 0.0005, '30_FR2': 0.0001, '30_FR3': 0.0, '30_Inside': 0.0004, '31_Gtl': 0.0009, '31_Mod': 0.0001, '31_Sev': 0.0002, '32_Blmngtn': 0.0002, '32_Blueste': 0.0, '32_BrDale': 0.0, '32_BrkSide': 0.0001, '32_ClearCr': 0.0004, '32_CollgCr': 0.0003, '32_Crawfor': 0.0016, '32_Edwards': 0.0002, '32_Gilbert': 0.0001, '32_IDOTRR': 0.0001, '32_MeadowV': 0.0, '32_Mitchel': 0.0001, '32_NAmes': 0.0004, '32_NPkVill': 0.0, '32_NWAmes': 0.0001, '32_NoRidge': 0.0004, '32_NridgHt': 0.0002, '32_OldTown': 0.0003, '32_SWISU': 0.0001, '32_Sawyer': 0.0001, '32_SawyerW': 0.0001, '32_Somerst': 0.0002, '32_StoneBr': 0.0006, '32_Timber': 0.0004, '32_Veenker': 0.0, '33_Artery': 0.0002, '33_Feedr': 0.0001, '33_Norm': 0.0002, '33_PosA': 0.0001, '33_PosN': 0.0001, '33_RRAe': 0.0, '33_RRAn': 0.0001, '33_RRNe': 0.0, '33_RRNn': 0.0, '34_Artery': 0.0, '34_Feedr': 0.0, '34_Norm': 0.0, '34_PosA': 0.0, '34_PosN': 0.0, '34_RRAe': 0.0, '34_RRAn': 0.0, '34_RRNn': 0.0, '35_1Fam': 0.0006, '35_2fmCon': 0.0, '35_Duplex': 0.0002, '35_Twnhs': 0.0, '35_TwnhsE': 0.0001, '36_1.5Fin': 0.0002, '36_1.5Unf': 0.0, '36_1Story': 0.0003, '36_2.5Fin': 0.0001, '36_2.5Unf': 0.0, '36_2Story': 0.0005, '36_SFoyer': 0.0, '36_SLvl': 0.0001, '37_Flat': 0.0, '37_Gable': 0.0005, '37_Gambrel': 0.0001, '37_Hip': 0.0005, '37_Mansard': 0.0, '37_Shed': 0.0, '38_CompShg': 0.0003, '38_Membran': 0.0001, '38_Metal': 0.0, '38_Roll': 0.0, '38_Tar&Grv': 0.0, '38_WdShake': 0.0, '38_WdShngl': 0.0002, '39_AsbShng': 0.0, '39_AsphShn': 0.0, '39_BrkComm': 0.0001, '39_BrkFace': 0.0003, '39_CBlock': 0.0, '39_CemntBd': 0.0001, '39_HdBoard': 0.0003, '39_ImStucc': 0.0, '39_MetalSd': 0.0001, '39_Plywood': 0.0001, '39_Stone': 0.0, '39_Stucco': 0.0001, '39_VinylSd': 0.0005, '39_Wd Sdng': 0.0002, '39_WdShing': 0.0, '40_AsbShng': 0.0, '40_AsphShn': 0.0, '40_Brk Cmn': 0.0, '40_BrkFace': 0.0002, '40_CBlock': 0.0, '40_CmentBd': 0.0003, '40_HdBoard': 0.0002, '40_ImStucc': 0.0001, '40_MetalSd': 0.0002, '40_Other': 0.0, '40_Plywood': 0.0001, '40_Stone': 0.0, '40_Stucco': 0.0001, '40_VinylSd': 0.0006, '40_Wd Sdng': 0.0002, '40_Wd Shng': 0.0003, '41_BrkTil': 0.0002, '41_CBlock': 0.0003, '41_PConc': 0.0003, '41_Slab': 0.0, '41_Stone': 0.0, '41_Wood': 0.0, '42_Floor': 0.0, '42_GasA': 0.0001, '42_GasW': 0.0001, '42_Grav': 0.0, '42_OthW': 0.0, '42_Wall': 0.0, '43_2Types': 0.0, '43_Attchd': 0.0004, '43_Basment': 0.0, '43_BuiltIn': 0.0002, '43_CarPort': 0.0, '43_Detchd': 0.0004, '44_COD': 0.0001, '44_CWD': 0.0001, '44_Con': 0.0, '44_ConLD': 0.0, '44_ConLI': 0.0, '44_ConLw': 0.0, '44_New': 0.0002, '44_Oth': 0.0, '44_WD': 0.001, '45_Abnorml': 0.0002, '45_AdjLand': 0.0, '45_Alloca': 0.0001, '45_Family': 0.0005, '45_Normal': 0.0004, '45_Partial': 0.0002}\n",
      "(1452, 120) (1452,)\n"
     ]
    }
   ],
   "source": [
    "#Feature selection 2\n",
    "rfr = RandomForestRegressor(random_state=42)\n",
    "rfr.fit(X_trans, y)\n",
    "\n",
    "feature_importance_dict = {}\n",
    "for feature, importance in zip(X_trans.columns, rfr.feature_importances_):\n",
    "    feature_importance_dict[feature] = importance.round(4)\n",
    "print(feature_importance_dict)\n",
    "\n",
    "important_features = [col for col in feature_importance_dict if feature_importance_dict[col] > 0]\n",
    "X_trans_final = X_trans[important_features]\n",
    "print(X_trans_final.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca67a3d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:20.640229Z",
     "iopub.status.busy": "2023-10-31T11:13:20.639125Z",
     "iopub.status.idle": "2023-10-31T11:13:20.655027Z",
     "shell.execute_reply": "2023-10-31T11:13:20.653255Z"
    },
    "papermill": {
     "duration": 0.027046,
     "end_time": "2023-10-31T11:13:20.657923",
     "exception": false,
     "start_time": "2023-10-31T11:13:20.630877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1016, 120) (1016,) (436, 120) (436,)\n"
     ]
    }
   ],
   "source": [
    "#Train & Test sets preparation\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_trans_final, y, test_size=0.3, random_state=42,)\n",
    "print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "443eb53b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:13:20.673591Z",
     "iopub.status.busy": "2023-10-31T11:13:20.673149Z",
     "iopub.status.idle": "2023-10-31T11:26:27.705355Z",
     "shell.execute_reply": "2023-10-31T11:26:27.703442Z"
    },
    "papermill": {
     "duration": 787.051704,
     "end_time": "2023-10-31T11:26:27.716412",
     "exception": false,
     "start_time": "2023-10-31T11:13:20.664708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=3, estimator=SGDRegressor(max_iter=10000, random_state=42),\n",
      "             param_grid={'alpha': [10, 0.1, 0.001, 1e-05],\n",
      "                         'eta0': [0.1, 0.01, 0.001]},\n",
      "             scoring='neg_root_mean_squared_error') train accuracy:  -22669.342\n",
      "GridSearchCV(cv=3, estimator=SGDRegressor(max_iter=10000, random_state=42),\n",
      "             param_grid={'alpha': [10, 0.1, 0.001, 1e-05],\n",
      "                         'eta0': [0.1, 0.01, 0.001]},\n",
      "             scoring='neg_root_mean_squared_error') valid accuracy:  -24122.598\n",
      "{'alpha': 0.001, 'eta0': 0.001}\n",
      "GridSearchCV(cv=3,\n",
      "             estimator=LinearSVR(C=1000, epsilon=10000, max_iter=10000,\n",
      "                                 random_state=42, tol=0.001),\n",
      "             param_grid={'C': [100, 1000, 10000, 100000],\n",
      "                         'epsilon': [100, 1000, 10000, 100000]},\n",
      "             scoring='neg_root_mean_squared_error') train accuracy:  -22905.885\n",
      "GridSearchCV(cv=3,\n",
      "             estimator=LinearSVR(C=1000, epsilon=10000, max_iter=10000,\n",
      "                                 random_state=42, tol=0.001),\n",
      "             param_grid={'C': [100, 1000, 10000, 100000],\n",
      "                         'epsilon': [100, 1000, 10000, 100000]},\n",
      "             scoring='neg_root_mean_squared_error') valid accuracy:  -23268.625\n",
      "{'C': 10000, 'epsilon': 10000}\n",
      "GridSearchCV(cv=3, estimator=RandomForestRegressor(n_jobs=-1, random_state=42),\n",
      "             param_grid={'max_depth': [1, 10, 100, 1000],\n",
      "                         'max_features': [0.125, 0.25, 0.5, 0.75],\n",
      "                         'max_samples': [0.25, 0.5, 0.75, 1],\n",
      "                         'n_estimators': [10, 50, 100, 500]},\n",
      "             scoring='neg_root_mean_squared_error') train accuracy:  -13967.41\n",
      "GridSearchCV(cv=3, estimator=RandomForestRegressor(n_jobs=-1, random_state=42),\n",
      "             param_grid={'max_depth': [1, 10, 100, 1000],\n",
      "                         'max_features': [0.125, 0.25, 0.5, 0.75],\n",
      "                         'max_samples': [0.25, 0.5, 0.75, 1],\n",
      "                         'n_estimators': [10, 50, 100, 500]},\n",
      "             scoring='neg_root_mean_squared_error') valid accuracy:  -23486.775\n",
      "{'max_depth': 10, 'max_features': 0.25, 'max_samples': 0.75, 'n_estimators': 100}\n",
      "GridSearchCV(cv=3,\n",
      "             estimator=GradientBoostingRegressor(n_estimators=1000,\n",
      "                                                 random_state=42),\n",
      "             param_grid={'learning_rate': [1, 0.1, 0.01, 0.001],\n",
      "                         'max_features': [0.05, 0.125, 0.25, 0.5],\n",
      "                         'subsample': [0.125, 0.25, 0.5, 0.75]},\n",
      "             scoring='neg_root_mean_squared_error') train accuracy:  -16659.629\n",
      "GridSearchCV(cv=3,\n",
      "             estimator=GradientBoostingRegressor(n_estimators=1000,\n",
      "                                                 random_state=42),\n",
      "             param_grid={'learning_rate': [1, 0.1, 0.01, 0.001],\n",
      "                         'max_features': [0.05, 0.125, 0.25, 0.5],\n",
      "                         'subsample': [0.125, 0.25, 0.5, 0.75]},\n",
      "             scoring='neg_root_mean_squared_error') valid accuracy:  -22277.312\n",
      "{'learning_rate': 0.01, 'max_features': 0.125, 'subsample': 0.25}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_features=0.125,\n",
       "                          n_estimators=1000, random_state=42, subsample=0.25)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor(learning_rate=0.01, max_features=0.125,\n",
       "                          n_estimators=1000, random_state=42, subsample=0.25)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingRegressor(learning_rate=0.01, max_features=0.125,\n",
       "                          n_estimators=1000, random_state=42, subsample=0.25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hyperparameter tuning\n",
    "sgdr = SGDRegressor(random_state=42, max_iter=10000, tol=1e-3)\n",
    "lsvr = LinearSVR(random_state=42, C=1000, epsilon=10000, max_iter=10000, tol=1e-3)\n",
    "rfr = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "gbr = GradientBoostingRegressor(random_state=42, n_estimators=1000)\n",
    "\n",
    "# score_model(sgdr, X_train, y_train, X_valid, y_valid)\n",
    "# score_model(lsvr, X_train, y_train, X_valid, y_valid)\n",
    "# score_model(rfr, X_train, y_train, X_valid, y_valid)\n",
    "# score_model(gbr, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "param_grid0 = {'alpha': [10, 0.1, 0.001, 0.00001], 'eta0': [0.1, 0.01, 0.001]}\n",
    "param_grid1 = {'C': [100, 1000, 10000, 100000], 'epsilon': [100, 1000, 10000, 100000]}\n",
    "param_grid2 = {'max_depth': [1, 10, 100, 1000], 'max_features': [0.125, 0.25, 0.5, 0.75], \n",
    "               'max_samples': [0.25, 0.5, 0.75, 1], 'n_estimators': [10, 50, 100, 500]}\n",
    "param_grid3 = {'learning_rate': [1, 0.1, 0.01, 0.001], 'max_features': [0.05, 0.125, 0.25, 0.5], \n",
    "               'subsample': [0.125, 0.25, 0.5, 0.75]}\n",
    "\n",
    "gscv_sgdr = GridSearchCV(sgdr, param_grid0, cv=3, scoring='neg_root_mean_squared_error')\n",
    "gscv_lsvr = GridSearchCV(lsvr, param_grid1, cv=3, scoring='neg_root_mean_squared_error')\n",
    "gscv_rfr = GridSearchCV(rfr, param_grid2, cv=3, scoring='neg_root_mean_squared_error')\n",
    "gscv_gbr = GridSearchCV(gbr, param_grid3, cv=3, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "score_model(gscv_sgdr, X_train, y_train, X_valid, y_valid)\n",
    "print(gscv_sgdr.best_params_)\n",
    "score_model(gscv_lsvr, X_train, y_train, X_valid, y_valid)\n",
    "print(gscv_lsvr.best_params_)\n",
    "score_model(gscv_rfr, X_train, y_train, X_valid, y_valid)\n",
    "print(gscv_rfr.best_params_)\n",
    "score_model(gscv_gbr, X_train, y_train, X_valid, y_valid)\n",
    "print(gscv_gbr.best_params_)\n",
    "\n",
    "sgdr.set_params(**gscv_sgdr.best_params_)\n",
    "lsvr.set_params(**gscv_lsvr.best_params_)\n",
    "rfr.set_params(**gscv_rfr.best_params_)\n",
    "gbr.set_params(**gscv_gbr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86d481cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:26:27.734401Z",
     "iopub.status.busy": "2023-10-31T11:26:27.733925Z",
     "iopub.status.idle": "2023-10-31T11:26:42.404042Z",
     "shell.execute_reply": "2023-10-31T11:26:42.402204Z"
    },
    "papermill": {
     "duration": 14.685484,
     "end_time": "2023-10-31T11:26:42.409864",
     "exception": false,
     "start_time": "2023-10-31T11:26:27.724380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22021.922170483922\n",
      "21613.579973229167\n"
     ]
    }
   ],
   "source": [
    "#Model training\n",
    "sr = StackingRegressor(estimators=[\n",
    "    #('sgdr', sgdr), \n",
    "    ('lsvr', lsvr), \n",
    "    ('rfr', rfr), \n",
    "    ('gbr', gbr)\n",
    "], cv=3)\n",
    "vr = VotingRegressor(estimators=[\n",
    "    #('sgdr', sgdr), \n",
    "    ('lsvr', lsvr), \n",
    "    ('rfr', rfr), \n",
    "    ('gbr', gbr), \n",
    "    ('sr', sr)\n",
    "])\n",
    "sr.fit(X_train, y_train)\n",
    "print(mean_squared_error(y_valid, sr.predict(X_valid), squared=False))\n",
    "vr.fit(X_train, y_train)\n",
    "print(mean_squared_error(y_valid, vr.predict(X_valid), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b79c33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:26:42.438266Z",
     "iopub.status.busy": "2023-10-31T11:26:42.437776Z",
     "iopub.status.idle": "2023-10-31T11:26:51.649910Z",
     "shell.execute_reply": "2023-10-31T11:26:51.648394Z"
    },
    "papermill": {
     "duration": 9.226735,
     "end_time": "2023-10-31T11:26:51.653892",
     "exception": false,
     "start_time": "2023-10-31T11:26:42.427157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16559.706046201747\n",
      "(1459, 120)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n",
      "/tmp/ipykernel_20/2742977636.py:33: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_trans_final[col] = X_trans[col]\n"
     ]
    }
   ],
   "source": [
    "#Final preparation\n",
    "vr.fit(X_trans_final, y)\n",
    "print(mean_squared_error(y, vr.predict(X_trans_final), squared=False))\n",
    "\n",
    "map_feature(X_test, to_map0, ordinal_mapping0)\n",
    "map_feature(X_test, to_map1, ordinal_mapping1)\n",
    "map_feature(X_test, to_map2, ordinal_mapping2)\n",
    "map_feature(X_test, to_map3, ordinal_mapping3)\n",
    "map_feature(X_test, to_map4, ordinal_mapping4)\n",
    "map_feature(X_test, to_map5, ordinal_mapping5)\n",
    "map_feature(X_test, to_map6, ordinal_mapping6)\n",
    "\n",
    "X_final = X_test[good_features0].join(X_test[good_features1])\n",
    "X_final['HouseQualCond'] = (X_test[['OverallCond', 'OverallQual', 'HeatingQC', 'FireplaceQu', 'CentralAir', 'Electrical', 'Functional']].sum(axis=1)) * (X_test.YearBuilt + X_test.YearRemodAdd + X_test.GarageYrBlt.fillna(1400) - X_test.YrSold)\n",
    "X_final['TotalArea'] = X_test.GrLivArea + ((X_test.GarageCars + X_test.GarageFinish) * X_test.GarageArea)\n",
    "X_final['TotalSF'] = X_test[['TotalBsmtSF', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', '1stFlrSF', '2ndFlrSF', 'WoodDeckSF', 'OpenPorchSF']].sum(axis=1) - X_test.LowQualFinSF\n",
    "X_final['TotalBath'] = X_test[['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath']].sum(axis=1)\n",
    "X_final['TotalRms'] = X_test.TotRmsAbvGrd - X_test.BedroomAbvGr\n",
    "X_final['OverallQualCond'] = X_test[['ExterQual', 'ExterCond', 'KitchenQual', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', 'HeatingQC', 'FireplaceQu']].sum(axis=1)\n",
    "\n",
    "poly_transform(X_final, to_poly_2)\n",
    "poly_transform(X_final, to_poly_3, 3)\n",
    "\n",
    "X_final = X_final.join(X_test.select_dtypes([object]))\n",
    "\n",
    "X_trans = pd.DataFrame(column_transformer.transform(X_final))\n",
    "X_trans = pd.get_dummies(X_trans, columns=range(25, 46))\n",
    "X_trans.columns = X_trans.columns.astype(str)\n",
    "\n",
    "X_trans_final = pd.DataFrame(index=X_test.index)\n",
    "for col in important_features:\n",
    "    if col in X_trans.columns:\n",
    "        X_trans_final[col] = X_trans[col]\n",
    "    else:\n",
    "        X_trans_final[col] = 0\n",
    "print(X_trans_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9bee10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-31T11:26:51.673050Z",
     "iopub.status.busy": "2023-10-31T11:26:51.672551Z",
     "iopub.status.idle": "2023-10-31T11:26:52.025626Z",
     "shell.execute_reply": "2023-10-31T11:26:52.023748Z"
    },
    "papermill": {
     "duration": 0.367131,
     "end_time": "2023-10-31T11:26:52.029081",
     "exception": false,
     "start_time": "2023-10-31T11:26:51.661950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save test predictions to file\n",
    "output = pd.DataFrame({'Id': X_test.index+1461,\n",
    "                       'SalePrice': vr.predict(X_trans_final)})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de20287",
   "metadata": {
    "papermill": {
     "duration": 0.00795,
     "end_time": "2023-10-31T11:26:52.046240",
     "exception": false,
     "start_time": "2023-10-31T11:26:52.038290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 823.363511,
   "end_time": "2023-10-31T11:26:52.981890",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-31T11:13:09.618379",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
